{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" parameters \"\"\"\n",
    "\n",
    "# data\n",
    "data_fold_cpu = \"/mnt/efs_v2/tag_onc/users/tianrui.qi/TCGA-Onc/data/\"\n",
    "data_fold_gpu = \"data/\"\n",
    "# parameter\n",
    "chr = \"6\"\n",
    "pval_thresh = 1e-5\n",
    "# method\n",
    "umap_fold = \"ckpt/umap/\"\n",
    "umap_ckpt = \"01\"    # {umap_fold}/{umap_ckpt}.sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import \"\"\"\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import cuml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unable to import Triton*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" profile \"\"\"\n",
    "\n",
    "# dataset\n",
    "profile = pd.read_csv(os.path.join(data_fold_cpu, \"profile.txt\"))\n",
    "# Isolate string (i.e. su001) -> int (i.e. 1)\n",
    "profile[\"Isolate\"] = profile[\"Isolate\"].apply(lambda x: int(x[2:]))\n",
    "# Treatment pre/post -> 0/1\n",
    "profile[\"Treatment\"] = profile[\"Treatment\"].apply(lambda x: int(not \"pre\" in x))\n",
    "# Sort by Isolate (1 to 8), Treatment (pre to post), and Tissue (normal to BCC)\n",
    "profile = profile.sort_values(\n",
    "    by=[\"Isolate\", \"Treatment\", \"Tissue\"], ascending=[True, True, False]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DNABERT2 Embedding \"\"\"\n",
    "\n",
    "def getEmbedding(csv: pd.DataFrame, batch_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate embedding of all sequences in the csv. \n",
    "\n",
    "    Args:\n",
    "        csv: pd.DataFrame, check README.md for the format.\n",
    "        batch_size: int, batch size for the calculation.\n",
    "\n",
    "    Returns:\n",
    "        embedding: np.ndarray, the embedding of all sequences in the csv with\n",
    "            shape (len(csv), 768).\n",
    "    \"\"\"\n",
    "    # model for embedding\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        \"zhihan1996/DNABERT-2-117M\", trust_remote_code=True\n",
    "    )\n",
    "    dnabert2 = transformers.AutoModel.from_pretrained(\n",
    "        \"zhihan1996/DNABERT-2-117M\", trust_remote_code=True\n",
    "    ).to(device).eval()\n",
    "\n",
    "    embedding = None\n",
    "    for i in range(int(np.ceil(len(csv) / batch_size))):\n",
    "        # sequence\n",
    "        sequence_batch = csv[\"sequence\"].iloc[\n",
    "            i*batch_size:(i+1)*batch_size\n",
    "        ].to_list()\n",
    "        # token\n",
    "        token_batch = tokenizer(\n",
    "            sequence_batch, return_tensors = 'pt', padding=True\n",
    "        )[\"input_ids\"].to(device)\n",
    "        # embedding\n",
    "        with torch.no_grad(): \n",
    "            embedding_batch = torch.mean(\n",
    "                dnabert2(token_batch)[0], dim=1\n",
    "            ).detach().cpu().numpy()\n",
    "        # save\n",
    "        embedding = np.concatenate(\n",
    "            [embedding, embedding_batch], axis=0\n",
    "        ) if embedding is not None else embedding_batch\n",
    "    return embedding\n",
    "\n",
    "embedding_dnabert2: dict[str, np.ndarray] = {run: None for run in profile[\"Run\"]}\n",
    "for run in tqdm.tqdm(profile[\"Run\"], smoothing=0.0, unit=\"run\"):\n",
    "    # load the csv, filter reads that pass the pval_thresh\n",
    "    csv = pd.read_csv(os.path.join(data_fold_cpu, \"csv\", f\"{run}/{chr}.csv\"))\n",
    "    csv = csv[csv[str(pval_thresh)]>=1]\n",
    "    # calculate the embedding by batch\n",
    "    embedding_dnabert2[run] = getEmbedding(csv, batch_size=int(1e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" UMAP \"\"\"\n",
    "\n",
    "umap_path = os.path.join(umap_fold, f\"{umap_ckpt}.sav\")\n",
    "if os.path.exists(umap_path):\n",
    "    reducer = joblib.load(umap_path)\n",
    "else:\n",
    "    embedding = np.concatenate([embedding_dnabert2[run] for run in profile[\"Run\"]], axis=0)\n",
    "    reducer = cuml.UMAP(n_components=2)\n",
    "    reducer.fit(embedding)\n",
    "    joblib.dump(reducer, umap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" UMAP Embedding \"\"\"\n",
    "\n",
    "embedding_umap = {}\n",
    "embedding_umap_save_fold = os.path.join(data_fold_gpu, f\"dnabert2_umap{umap_ckpt}/chr{chr}_pval{int(-np.log10(pval_thresh))}\")\n",
    "if not os.path.exists(embedding_umap_save_fold):\n",
    "    os.makedirs(embedding_umap_save_fold)\n",
    "for run in tqdm.tqdm(profile[\"Run\"], smoothing=0.0, unit=\"run\"):\n",
    "    embedding_umap_save_path = os.path.join(embedding_umap_save_fold, f\"{run}.csv\")\n",
    "    if os.path.exists(embedding_umap_save_path):\n",
    "        embedding_umap[run] = np.loadtxt(embedding_umap_save_path, delimiter=\",\")\n",
    "    else:\n",
    "        embedding_umap[run] = reducer.transform(embedding_dnabert2[run])\n",
    "        np.savetxt(embedding_umap_save_path, embedding_umap[run], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" hexbin map for all sample \"\"\"\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    4, 6, figsize=(30, 20), sharex=True, sharey=True, dpi=500\n",
    ")\n",
    "index = -1\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i == 11:\n",
    "        ax.axis(\"off\")\n",
    "        continue\n",
    "    index += 1\n",
    "\n",
    "    ax.hexbin(\n",
    "        embedding_umap[profile[\"Run\"][index]][:, 0], \n",
    "        embedding_umap[profile[\"Run\"][index]][:, 1], \n",
    "        gridsize=150,\n",
    "        cmap=\"Reds\",\n",
    "        vmin=2, vmax=80,\n",
    "    )\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color(\"r\" if profile[\"Treatment\"][index] == 0 else \"b\")\n",
    "        spine.set_linewidth(2)\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(-16, 16)\n",
    "    ax.set_ylim(-16, 16)\n",
    "    ax.set_title(\n",
    "        \"Run: {}; \".format(profile[\"Run\"][index]) + \n",
    "        \"Isolate: {};\".format(profile[\"Isolate\"][index])\n",
    "    )\n",
    "fig.legend(\n",
    "    handles=[\n",
    "        matplotlib.patches.Patch(color=\"r\", label=\"pre \"), \n",
    "        matplotlib.patches.Patch(color=\"b\", label=\"post\")\n",
    "    ], loc=\"upper right\", ncol=2, fontsize=14,\n",
    ")\n",
    "fig.suptitle(\n",
    "    f\"Stanford Data; chromosome {chr}; SNPs p-val threshold (<=) {pval_thresh}\", \n",
    "    fontweight='bold', y=0.992, fontsize=16\n",
    ")\n",
    "fig.supxlabel(\"UMAP1\", fontweight='bold', y=0.005, fontsize=16)\n",
    "fig.supylabel(\"UMAP2\", fontweight='bold', x=0.010, fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\n",
    "    os.path.join(embedding_umap_save_fold, \"hexbin.png\"), \n",
    "    dpi=500,\n",
    ")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCGA-Onc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
