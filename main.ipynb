{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import sklearn.decomposition\n",
    "import sklearn.svm, sklearn.linear_model\n",
    "import sklearn.metrics, sklearn.preprocessing\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import src\n",
    "import temp_embd2repre\n",
    "\n",
    "chromosome_list = [str(i) for i in range(1, 23)] + [\"X\"]\n",
    "\n",
    "profile_v1 = pd.read_csv(\"data/develop/v1/profile.csv\")\n",
    "profile_v2 = pd.read_csv(\"data/develop/v2/profile.csv\")\n",
    "\n",
    "def getFeature(chromosome: str, version: int, unit: str):\n",
    "    # read the feature\n",
    "    if version == 1:\n",
    "        selector = temp_embd2repre.Selector(\"data/develop/v1/feature/{}\".format(chromosome))\n",
    "        feature = selector[:]\n",
    "    if version == 2:\n",
    "        selector = src.Selector(\"data/develop/v2/feature\")\n",
    "        feature = selector.getFeature(chromosome)\n",
    "\n",
    "    # transform the feature if needed\n",
    "    if version == 2 and unit == \"position\":\n",
    "        position = feature[:, 0] * 1000 + feature[:, 1] * 100 + 50\n",
    "        feature = np.column_stack((position, feature[:, 2]))\n",
    "        feature = feature[np.lexsort((-feature[:, 1],))]\n",
    "    if version == 1 and unit == \"bucket\":\n",
    "        hash_idx = feature[:, 0] // 1000\n",
    "        bucket_idx = (feature[:, 0] % 1000) // 100\n",
    "        feature = np.column_stack((hash_idx, bucket_idx, feature[:, 1]))\n",
    "        feature = feature[np.lexsort((feature[:, 1], feature[:, 0]))]\n",
    "\n",
    "    # unit == \"position\":\n",
    "    #   (position, distance), sort by distance\n",
    "    # unit == \"bucket\":\n",
    "    #   (hash_idx, bucket_idx, distance), sort by hash_idx and bucket_idx\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" embd_stanford and mean \"\"\"\n",
    "\n",
    "embd_stanford = {sample: None for sample in profile_v1[\"sample\"]}\n",
    "for chromosome in chromosome_list:\n",
    "    selection = temp_embd2repre.Selector(\n",
    "        os.path.join(\"data/develop/v1/feature\", chromosome)\n",
    "    )\n",
    "    for i in tqdm.tqdm(range(len(profile_v1))):\n",
    "        embd_temp = selection.apply(\n",
    "            os.path.join(profile_v1[\"embd_fold\"].iloc[i], f\"{chromosome}.npy\")\n",
    "        )\n",
    "        if embd_stanford[profile_v1[\"sample\"].iloc[i]] is None: \n",
    "            embd_stanford[profile_v1[\"sample\"].iloc[i]] = embd_temp\n",
    "        else:\n",
    "            embd_stanford[profile_v1[\"sample\"].iloc[i]] = np.concatenate(\n",
    "                (embd_stanford[profile_v1[\"sample\"].iloc[i]], embd_temp), axis=0\n",
    "            )\n",
    "# combine all embd, remove all the nan row\n",
    "embd_all = np.concatenate([embd_stanford[s] for s in profile_v1[\"sample\"]], axis=0)\n",
    "embd_all = embd_all[~np.isnan(embd_all).all(axis=1)]\n",
    "# calculate the mean and fill the embd nan row with mean\n",
    "# so that these nan will be 0 in pca\n",
    "mean = np.mean(embd_all, axis=0)\n",
    "for e in profile_v1[\"sample\"]:\n",
    "    embd_stanford[e] = np.where(np.isnan(embd_stanford[e]), mean, embd_stanford[e])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pca_reducer_1: pca for len(runs) * [N,768] -> [len(runs), N] \"\"\"\n",
    "\n",
    "pca_reducer_1 = sklearn.decomposition.PCA()\n",
    "pca_reducer_1.fit(embd_all)\n",
    "print(\"pca_reducer_1\", pca_reducer_1.explained_variance_ratio_[:5])\n",
    "\n",
    "pca_1_stanford = np.array([pca_reducer_1.transform(embd_stanford[s]) for s in profile_v1[\"sample\"]])[:, :, 0]\n",
    "\n",
    "\"\"\" pca_reducer_2: pca for [len(runs), N] -> [len(runs), 10] \"\"\"\n",
    "\n",
    "pca_reducer_2 = sklearn.decomposition.PCA(n_components=10)\n",
    "pca_2_stanford = pca_reducer_2.fit_transform(pca_1_stanford)\n",
    "print(\"pca_reducer_2\", pca_reducer_2.explained_variance_ratio_[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare feature of v1 and v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = getFeature(\"6\", 1, \"position\")\n",
    "upper = int(np.ceil(feature[0, 1]))\n",
    "lower = int(np.floor(feature[-1, 1]))\n",
    "# 10%\n",
    "upper_10 = feature[int(len(feature)*0.1), 1]\n",
    "plt.axvline(upper_10, color=\"black\", linestyle=\"--\")\n",
    "plt.text(upper_10+0.1, plt.ylim()[1]*1000, \"10%\")\n",
    "# 50%\n",
    "upper_50 = feature[int(len(feature)*0.5), 1]\n",
    "plt.axvline(upper_50, color=\"black\", linestyle=\"--\")\n",
    "plt.text(upper_50+0.1, plt.ylim()[1]*1000, \"50%\")\n",
    "# hist\n",
    "plt.hist(feature[:, 1], bins=100, color=\"salmon\")\n",
    "plt.xlim(lower, upper)\n",
    "plt.title(\"Distribution of Features' Distance of Chromosome 6\")\n",
    "plt.xlabel(\"Euclidean Distance\")\n",
    "plt.ylabel(\"Number of Features(Positions)\")\n",
    "plt.show()\n",
    "print(feature[:10, 0].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = getFeature(\"6\", 2, \"position\")\n",
    "upper = int(np.ceil(feature[0, 1]))\n",
    "lower = int(np.floor(feature[-1, 1]))\n",
    "# 10%\n",
    "upper_10 = feature[int(len(feature)*0.1), 1]\n",
    "plt.axvline(upper_10, color=\"black\", linestyle=\"--\")\n",
    "plt.text(upper_10+0.1, plt.ylim()[1]*2700, \"10%\")\n",
    "# 50%\n",
    "upper_50 = feature[int(len(feature)*0.5), 1]\n",
    "plt.axvline(upper_50, color=\"black\", linestyle=\"--\")\n",
    "plt.text(upper_50+0.1, plt.ylim()[1]*2700, \"50%\")\n",
    "# hist\n",
    "plt.hist(feature[:, 1], bins=100, color=\"salmon\")\n",
    "plt.xlim(lower, upper)\n",
    "plt.xlabel(\"Euclidean Distance\")\n",
    "plt.ylabel(\"Number of Features/Buckets\")\n",
    "plt.show()\n",
    "print(feature[:10, 0].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = profile_v1[\"sample\"]\n",
    "profile_v2 = profile_v2[profile_v2[\"sample\"].isin(sample)]\n",
    "\n",
    "selector = src.Selector(\"data/develop/v2/feature\")\n",
    "repre = selector.getRepre(profile_v2[\"embd_fold\"], verbal=False)\n",
    "\n",
    "# pca to visualize the representation\n",
    "pca = sklearn.decomposition.PCA(n_components=6)\n",
    "repre_pca = pca.fit_transform(repre[:23])\n",
    "# plot, color by profile[\"dataset\"]\n",
    "#color = [\"red\" if i == \"stanford\" else \"blue\" for i in profile_v2[\"dataset\"].to_list()[:23]]\n",
    "color = [\"red\" if i == \"pre anti-PD-1\" else \"blue\" for i in profile_v2[\"Treatment\"].to_list()[:23]]\n",
    "plt.scatter(repre_pca[:23, 0], repre_pca[:23, 1], c=color, s=2)\n",
    "plt.title(\"PCA of Representation\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a linear regression classifier using repre[:23] and label by profile_v2[\"Treatment\"].to_list()[:23]\n",
    "# not that treatment is string and need to be transformed into binary label\n",
    "# pre anti-PD-1 -> 0, anti-PD-1 -> 1\n",
    "label = [0 if i == \"pre anti-PD-1\" else 1 for i in profile_v2[\"Treatment\"].to_list()[:23]]\n",
    "print(label)\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(repre[:23], label)\n",
    "pred = clf.predict(repre[23:])\n",
    "print(pred)\n",
    "# calculate the accuracy\n",
    "accuracy = sklearn.metrics.accuracy_score(label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get representation and label\n",
    "profile = pd.read_csv(\"data/profile.csv\")\n",
    "profile = profile[profile[\"dataset\"] == \"stanford\"]\n",
    "repre = selector.getRepre(profile[\"embd_fold\"].to_list(), verbal=False)\n",
    "label = profile[\"Treatment\"].apply(lambda x: 0 if x == \"pre anti-PD-1\" else 1).to_list()\n",
    "# pca repre\n",
    "pca = sklearn.decomposition.PCA(n_components=8)\n",
    "repre_pca = pca.fit_transform(repre)\n",
    "# plot pca 1 and 2, color by label\n",
    "plt.scatter(repre_pca[:, 1], repre_pca[:, 2], c=label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repre = selector.getRepre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read profile\n",
    "profile = pd.read_csv(\"data/profile.csv\")\n",
    "profile = profile[profile[\"dataset\"] == \"tcgaskcm\"]\n",
    "profile = pd.concat([\n",
    "    profile[profile[\"easy\"] == 1], profile[profile[\"hard\"] == 1]\n",
    "]).reset_index(drop=True)\n",
    "# random sample train, valid, test using pandas sample\n",
    "profile_train = profile.sample(frac=0.6, random_state=0)\n",
    "profile_valid = profile.drop(profile_train.index).sample(frac=0.5, random_state=0)\n",
    "profile_test  = profile.drop(profile_train.index).drop(profile_valid.index)\n",
    "\n",
    "#profile_train = profile[profile[\"train\"] == 1]\n",
    "#profile_valid = profile[profile[\"valid\"] == 1]\n",
    "#profile_test  = profile[profile[\"test\"]  == 1]\n",
    "# representation\n",
    "repre_train = selector.getRepre(profile_train[\"embd_fold\"].to_list(), recalculate=False)   # (497, 768)\n",
    "repre_valid = selector.getRepre(profile_valid[\"embd_fold\"].to_list(), recalculate=False)   # (216, 768)\n",
    "repre_test  = selector.getRepre(profile_test[\"embd_fold\"].to_list(), recalculate=False)    # (215, 768)\n",
    "repre = np.vstack([repre_train, repre_valid, repre_test])               # (928, 768)\n",
    "# PCA\n",
    "pca = sklearn.decomposition.PCA(n_components=500)\n",
    "pca = pca.fit(repre)\n",
    "repre_train = pca.transform(repre_train)    # (497, 768)\n",
    "repre_valid = pca.transform(repre_valid)    # (216, 768)\n",
    "repre_test  = pca.transform(repre_test)     # (215, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(repre_train[:, 0], repre_train[:, 1], s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = 0, 100\n",
    "t1, t2 = 0.2, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## T Cells CD8\n",
    "# label\n",
    "label_train = profile_train[\"Leukocyte Fraction\"]\n",
    "label_valid = profile_valid[\"Leukocyte Fraction\"]\n",
    "label_test  = profile_test [\"Leukocyte Fraction\"]\n",
    "# prediction\n",
    "#model = sklearn.linear_model.LinearRegression().fit(repre_train[:, start:end], label_train)\n",
    "model = sklearn.svm.SVR().fit(repre_train[:, start:end], label_train)\n",
    "pred_train = model.predict(repre_train[:, start:end])\n",
    "pred_valid = model.predict(repre_valid[:, start:end])\n",
    "pred_test  = model.predict(repre_test[:, start:end])\n",
    "# performance\n",
    "mae_train = sklearn.metrics.mean_absolute_error(label_train, pred_train)\n",
    "mae_valid = sklearn.metrics.mean_absolute_error(label_valid, pred_valid)\n",
    "print(f\"train mae: {mae_train:.3f}\")\n",
    "print(f\"valid mae: {mae_valid:.3f}\")\n",
    "# view T Cells CD8 < 0.1 as low, 0.1 <= T Cells CD8 < 0.3 as middle, \n",
    "# 0.3 <= T Cells CD8 as high, check pred_valid and profile_valid[\"T Cells CD8\"]\n",
    "# performance in classification way\n",
    "label_class_train = np.digitize(label_train, [t1, t2])\n",
    "label_class_valid = np.digitize(label_valid, [t1, t2])\n",
    "pred_class_train = np.digitize(pred_train, [t1, t2])\n",
    "pred_class_valid = np.digitize(pred_valid, [t1, t2])\n",
    "# 3 * 3 confusion matrix\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(label_class_train, pred_class_train)\n",
    "print(confusion_matrix)\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(label_class_valid, pred_class_valid)\n",
    "print(confusion_matrix)\n",
    "# print accuracy\n",
    "accuracy_train = sklearn.metrics.accuracy_score(label_class_train, pred_class_train)\n",
    "accuracy_valid = sklearn.metrics.accuracy_score(label_class_valid, pred_class_valid)\n",
    "print(f\"train accuracy: {accuracy_train:.3f}\")\n",
    "print(f\"valid accuracy: {accuracy_valid:.3f}\")\n",
    "\n",
    "# plot pred_valid as x and label_valid as y\n",
    "plt.scatter(pred_train, label_train, color=\"blue\", s=10)\n",
    "plt.scatter(pred_valid, label_valid, color=\"red\", s=10)\n",
    "plt.plot([0, 0.5], [0, 0.5], color=\"black\")\n",
    "plt.xlabel(\"pred\")\n",
    "plt.ylabel(\"label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: prediction using Th2 Cells as lable and svm as model\n",
    "svm = sklearn.svm.SVR().fit(repre_train, profile_train[\"Th2 Cells\"])\n",
    "pred_train = svm.predict(repre_train)\n",
    "pred_valid = svm.predict(repre_valid)\n",
    "mae_train = sklearn.metrics.mean_absolute_error(profile_train[\"Th2 Cells\"], pred_train)\n",
    "mae_valid = sklearn.metrics.mean_absolute_error(profile_valid[\"Th2 Cells\"], pred_valid)\n",
    "print(f\"train mae: {mae_train:.2f}\")\n",
    "print(f\"valid mae: {mae_valid:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile 0: nan to 0\n",
    "# profile 1: remove nan row\n",
    "\n",
    "# representation\n",
    "profile = pd.read_csv(\"data/profile0.csv\")\n",
    "profile = profile.iloc[23:].reset_index(drop=True)\n",
    "repre = np.hstack([\n",
    "    np.load(profile.loc[i, \"repre_path\"]) for i in range(len(profile))\n",
    "    if not pd.isna(profile.loc[i, \"repre_path\"])\n",
    "]).T\n",
    "# for each column, if there are np.nan in that column, drop that column\n",
    "repre = repre[:, np.all(~np.isnan(repre), axis=0)]  # comment for 0, un for 1\n",
    "repre = np.nan_to_num(repre, nan=0.0)\n",
    "# fit\n",
    "visu_pca = sklearn.decomposition.PCA(n_components=8).fit(repre)\n",
    "visu_umap = umap.UMAP(n_components=3).fit(repre)\n",
    "# transform\n",
    "idx = [\n",
    "    i for i in range(len(profile)) if not pd.isna(profile.loc[i, \"repre_path\"])\n",
    "]\n",
    "profile.loc[idx, [f\"pca{p}\" for p in range(8)]] = visu_pca.transform(repre)\n",
    "profile.loc[idx, [f\"umap{u}\" for u in range(3)]] = visu_umap.transform(repre)\n",
    "# save\n",
    "profile.to_csv(\"data/profile2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# { chromosome : (hash_idx, bucket_idx, distance) }\n",
    "feature = Selector(\"data/feature\").getFeature()\n",
    "# remove distance and ndarray dtype from float to int\n",
    "# { chromosome : (hash_idx, bucket_idx) }\n",
    "feature = {c: np.array([f[:2] for f in feature[c]], dtype=int) for c in feature}\n",
    "result = []\n",
    "for c in chromosome_list:\n",
    "    for hash_idx, bucket_idx in feature[c]:\n",
    "        result.append((c, hash_idx*1000 + bucket_idx*100, hash_idx*1000 + (bucket_idx+1)*100))\n",
    "result = pd.DataFrame(result, columns=[\"chromosome\", \"start\", \"end\"])\n",
    "result.to_csv(\"data/temp/feature.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_idx_max = {\n",
    "    \"1\": 249000,  \"2\": 243000,  \"3\": 199000,  \"4\": 191000,\n",
    "    \"5\": 182000,  \"6\": 171000,  \"7\": 160000,  \"8\": 146000,\n",
    "    \"9\": 139000, \"10\": 134000, \"11\": 136000, \"12\": 134000,\n",
    "    \"13\": 115000, \"14\": 108000, \"15\": 102000, \"16\":  91000,\n",
    "    \"17\":  84000, \"18\":  81000, \"19\":  59000, \"20\":  65000,\n",
    "    \"21\":  47000, \"22\":  51000,  \"X\": 157000,\n",
    "}\n",
    "\n",
    "## bed\n",
    "# read bed file\n",
    "bed = pd.read_csv(\n",
    "    \"data/temp/rgc_gxs_v1_hg38.bed\", \n",
    "    sep=\"\\t\", header=0, names=[\"chromosome\", \"start\", \"end\"]\n",
    ")\n",
    "# remove chr prefix\n",
    "bed[\"chromosome\"] = bed[\"chromosome\"].apply(lambda x: x[3:])\n",
    "# keep chromosome 1-22 and X\n",
    "bed = bed[bed['chromosome'].isin(chromosome_list)]\n",
    "# transform bed from range list to one hot\n",
    "bed_one_hot = {\n",
    "    c: np.zeros((hash_idx_max[c] * 1000), dtype=bool) for c in chromosome_list\n",
    "}\n",
    "for _, row in bed.iterrows():\n",
    "    chromosome, start, end = row[['chromosome', 'start', 'end']]\n",
    "    bed_one_hot[chromosome][start:end] = True\n",
    "\n",
    "## feature\n",
    "# { chromosome : (hash_idx, bucket_idx, distance) }\n",
    "feature = Selector(\"data/feature\").getFeature()\n",
    "# remove distance and ndarray dtype from float to int\n",
    "# { chromosome : (hash_idx, bucket_idx) }\n",
    "feature = {c: np.array([f[:2] for f in feature[c]], dtype=int) for c in feature}\n",
    "# transform feature from bucket list to one hot\n",
    "feature_one_hot = {\n",
    "    c: np.zeros((hash_idx_max[c] * 1000), dtype=bool) for c in chromosome_list\n",
    "}\n",
    "for c in feature:\n",
    "    for hash_idx, bucket_idx in feature[c]:\n",
    "        feature_one_hot[c][\n",
    "            hash_idx*1000 + bucket_idx*100 : hash_idx*1000 + (bucket_idx+1)*100\n",
    "        ] = True\n",
    "\n",
    "# calculate overlap\n",
    "for c in bed_one_hot:\n",
    "    overlap = np.logical_and(bed_one_hot[c], feature_one_hot[c])\n",
    "    overlap_bed = (np.sum(overlap) / np.sum(bed_one_hot[c])) * 100 \n",
    "    overlap_feature = (np.sum(overlap) / np.sum(feature_one_hot[c])) * 100\n",
    "    print(\n",
    "        f\"Chromosome {c}:\\t\",\n",
    "        f\"overlap/bed: {np.sum(overlap):7,} / {np.sum(bed_one_hot[c]):9,} = {overlap_bed:5.2f}%\\t\",\n",
    "        f\"overlap/feature: {np.sum(overlap):7,} / {np.sum(feature_one_hot[c]):9,} = {overlap_feature:5.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = 1e-3\n",
    "\n",
    "snps = pd.read_csv(\"data/snps.csv\", usecols=[\"Chr\", \"Pos\", \"Pval\"])\n",
    "# filter by pval < 1e-3\n",
    "snps = snps[snps[\"Pval\"] < p_val][[\"Chr\", \"Pos\"]]\n",
    "# sort by Chr and then Pos\n",
    "snps = snps.sort_values([\"Chr\", \"Pos\"])\n",
    "# transform chromosome from int 1-23 to str 1-22, X\n",
    "snps[\"Chr\"] = snps[\"Chr\"].apply(lambda x: str(x) if x < 23 else \"X\")\n",
    "# split by chromosome, { chromosome : (pos) }\n",
    "snps = snps.groupby(\"Chr\")[\"Pos\"].apply(list).to_dict()\n",
    "\n",
    "for c, pos in snps.items():\n",
    "    snps_in_bed, snps_in_feature = 0, 0\n",
    "    for p in pos:\n",
    "        if bed_one_hot[c][p]: snps_in_bed += 1\n",
    "        if feature_one_hot[c][p]: snps_in_feature += 1\n",
    "    print(\n",
    "        f\"Chromosome {c}:\\t\",\n",
    "        f\"snps_in_bed/bed: {snps_in_bed:6,} / {len(pos):6,} = {(snps_in_bed / len(pos)) * 100:5.2f}%\\t\",\n",
    "        f\"snps_in_feature/feature: {snps_in_feature:6,} / {len(pos):6,} = {(snps_in_feature / len(pos)) * 100:5.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = 1e-2\n",
    "\n",
    "snps = pd.read_csv(\"data/snps.csv\", usecols=[\"Chr\", \"Pos\", \"Pval\"])\n",
    "# filter by pval < 1e-2\n",
    "snps = snps[snps[\"Pval\"] < p_val][[\"Chr\", \"Pos\"]]\n",
    "# sort by Chr and then Pos\n",
    "snps = snps.sort_values([\"Chr\", \"Pos\"])\n",
    "# transform chromosome from int 1-23 to str 1-22, X\n",
    "snps[\"Chr\"] = snps[\"Chr\"].apply(lambda x: str(x) if x < 23 else \"X\")\n",
    "# split by chromosome, { chromosome : (pos) }\n",
    "snps = snps.groupby(\"Chr\")[\"Pos\"].apply(list).to_dict()\n",
    "\n",
    "for c, pos in snps.items():\n",
    "    snps_in_bed, snps_in_feature = 0, 0\n",
    "    for p in pos:\n",
    "        if bed_one_hot[c][p]: snps_in_bed += 1\n",
    "        if feature_one_hot[c][p]: snps_in_feature += 1\n",
    "    print(\n",
    "        f\"Chromosome {c}:\\t\",\n",
    "        f\"snps_in_bed/bed: {snps_in_bed:7,} / {len(pos):7,} = {(snps_in_bed / len(pos)) * 100:5.2f}%\\t\",\n",
    "        f\"snps_in_feature/feature: {snps_in_feature:7,} / {len(pos):7,} = {(snps_in_feature / len(pos)) * 100:5.2f}%\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCGA-Onc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
