{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import sklearn.decomposition\n",
    "import sklearn.svm, sklearn.linear_model\n",
    "import sklearn.metrics, sklearn.preprocessing\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import pysam\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import Selector\n",
    "\n",
    "selector = Selector(\"data/feature\")\n",
    "\n",
    "chromosome_list = [str(i) for i in range(1, 23)] + [\"X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BAM and SNPs to Sequence\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# read hdf of given sample and chromosome\n",
    "hdf_path = \"temp/hdf/a.h5\"\n",
    "chromosome = \"2\"\n",
    "hdf = pd.read_hdf(hdf_path, key=f\"/chr{chromosome}\", mode='r')\n",
    "# filter reads that cover at least one variants with p-value<pval_thresh\n",
    "#pval_thresh = 1e-1\n",
    "#hdf = hdf[hdf[f\"{pval_thresh:.0e}\"]>=1]\n",
    "# glace\n",
    "print(f\"number of reads in {hdf_path}/chr{chromosome}: {len(hdf)}\")\n",
    "display(hdf.head())\n",
    "display(hdf.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequence to Embedding\n",
    "import numpy as np\n",
    "a = np.load(\"temp/instance/embd/a/2/000/016.npy\")\n",
    "print(a[:, 768])\n",
    "a = np.load(\"temp/instance/embd/a/2/000/017.npy\")\n",
    "print(a[:, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Feature (sample_idx, pos, embd_idx, distance)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from src.embd2repre import Selector\n",
    "\n",
    "#selector = Selector(\"temp/instance/feature\")\n",
    "#selector.addFeature([\"temp/instance/embd/a\", \"temp/instance/embd/b\"], chromosome=\"2\")\n",
    "#selector.addFeature([\"temp/instance/embd/c\"], chromosome=\"2\")\n",
    "\n",
    "print(\"feature 2/000/010\")\n",
    "print(np.load(\"temp/instance/feature/2/000/010.npy\")[:, 0])\n",
    "print(np.load(\"temp/instance/feature/2/000/010.npy\")[:, 1])\n",
    "print(\"sample a/2/000/010\")\n",
    "print(np.load(\"temp/instance/embd/a/2/000/010.npy\")[:, 768])\n",
    "print(\"sample b/2/000/010\")\n",
    "print(np.load(\"temp/instance/embd/b/2/000/010.npy\")[:, 768])\n",
    "print(\"sample c/2/000/010\")\n",
    "print(np.load(\"temp/instance/embd/c/2/000/010.npy\")[:, 768])\n",
    "print(\"feature 2/000/010\")\n",
    "print(np.load(\"temp/instance/feature/2/000/010.npy\")[:, 0])\n",
    "print(np.load(\"temp/instance/feature/2/000/010.npy\")[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getFeature { chromosome : (hash_idx, bucket_idx, distance) }\n",
    "\n",
    "from src.embd2repre import Selector\n",
    "\n",
    "selector = Selector(\"temp/feature\")\n",
    "feature_c = selector.getFeature(chromosome=\"2\")[\"2\"]\n",
    "\n",
    "print(feature_c.shape)\n",
    "print(\"hash_idx, bucket_idx, distance\")\n",
    "print(feature_c[:10])\n",
    "\n",
    "top_k = 0.15\n",
    "top_k = int(len(feature_c) * top_k)\n",
    "order = np.sort(np.argsort(feature_c[:, 2])[-top_k:])\n",
    "feature_c = feature_c[order]\n",
    "\n",
    "print(\"after select top 15% of feature\")\n",
    "print(\"hash_idx, bucket_idx, distance\")\n",
    "print(feature_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## applyFeature (:768 embd, 768 pos, 769 embd_idx)\n",
    "\n",
    "from src.embd2repre import Selector\n",
    "\n",
    "selector = Selector(\"temp/feature\")\n",
    "selector.applyFeature([\"temp/embd/a\", \"temp/embd/b\", \"temp/embd/c\"], chromosome=\"2\")\n",
    "\n",
    "feature = np.load(\"temp/embd/a/2/feature.npy\")\n",
    "print(feature[:, 768])\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read profile\n",
    "profile = pd.read_csv(\"data/profile.csv\")\n",
    "profile = profile[profile[\"dataset\"] == \"tcgaskcm\"]\n",
    "profile = pd.concat([\n",
    "    profile[profile[\"easy\"] == 1], profile[profile[\"hard\"] == 1]\n",
    "]).reset_index(drop=True)\n",
    "# random sample train, valid, test using pandas sample\n",
    "profile_train = profile.sample(frac=0.6, random_state=0)\n",
    "profile_valid = profile.drop(profile_train.index).sample(frac=0.5, random_state=0)\n",
    "profile_test  = profile.drop(profile_train.index).drop(profile_valid.index)\n",
    "\n",
    "#profile_train = profile[profile[\"train\"] == 1]\n",
    "#profile_valid = profile[profile[\"valid\"] == 1]\n",
    "#profile_test  = profile[profile[\"test\"]  == 1]\n",
    "# representation\n",
    "repre_train = np.hstack([np.load(row[\"repre_path\"]) for _, row in profile_train.iterrows()]).T  # (497, 768)\n",
    "repre_valid = np.hstack([np.load(row[\"repre_path\"]) for _, row in profile_valid.iterrows()]).T  # (216, 768)\n",
    "repre_test  = np.hstack([np.load(row[\"repre_path\"]) for _, row in profile_test.iterrows() ]).T  # (215, 768)\n",
    "repre = np.vstack([repre_train, repre_valid, repre_test])   # (928, 768)\n",
    "# PCA\n",
    "pca = sklearn.decomposition.PCA()\n",
    "pca = pca.fit(repre)\n",
    "repre_train = pca.transform(repre_train)    # (497, 768)\n",
    "repre_valid = pca.transform(repre_valid)    # (216, 768)\n",
    "repre_test  = pca.transform(repre_test)     # (215, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(repre_train[:, 0], repre_train[:, 1], s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = 0, 100\n",
    "t1, t2 = 0.4, 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## T Cells CD8\n",
    "# label\n",
    "label_train = profile_train[\"Leukocyte Fraction\"]\n",
    "label_valid = profile_valid[\"Leukocyte Fraction\"]\n",
    "label_test  = profile_test [\"Leukocyte Fraction\"]\n",
    "# prediction\n",
    "model = sklearn.linear_model.LinearRegression().fit(repre_train[:, start:end], label_train)\n",
    "#model = sklearn.svm.SVR().fit(repre_train[:, start:end], label_train)\n",
    "pred_train = model.predict(repre_train[:, start:end])\n",
    "pred_valid = model.predict(repre_valid[:, start:end])\n",
    "pred_test  = model.predict(repre_test[:, start:end])\n",
    "# performance\n",
    "mae_train = sklearn.metrics.mean_absolute_error(label_train, pred_train)\n",
    "mae_valid = sklearn.metrics.mean_absolute_error(label_valid, pred_valid)\n",
    "print(f\"train mae: {mae_train:.3f}\")\n",
    "print(f\"valid mae: {mae_valid:.3f}\")\n",
    "# view T Cells CD8 < 0.1 as low, 0.1 <= T Cells CD8 < 0.3 as middle, \n",
    "# 0.3 <= T Cells CD8 as high, check pred_valid and profile_valid[\"T Cells CD8\"]\n",
    "# performance in classification way\n",
    "label_class_train = np.digitize(label_train, [t1, t2])\n",
    "label_class_valid = np.digitize(label_valid, [t1, t2])\n",
    "pred_class_train = np.digitize(pred_train, [t1, t2])\n",
    "pred_class_valid = np.digitize(pred_valid, [t1, t2])\n",
    "# 3 * 3 confusion matrix\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(label_class_train, pred_class_train)\n",
    "print(confusion_matrix)\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(label_class_valid, pred_class_valid)\n",
    "print(confusion_matrix)\n",
    "# print accuracy\n",
    "accuracy_train = sklearn.metrics.accuracy_score(label_class_train, pred_class_train)\n",
    "accuracy_valid = sklearn.metrics.accuracy_score(label_class_valid, pred_class_valid)\n",
    "print(f\"train accuracy: {accuracy_train:.3f}\")\n",
    "print(f\"valid accuracy: {accuracy_valid:.3f}\")\n",
    "\n",
    "# plot pred_valid as x and label_valid as y\n",
    "plt.scatter(pred_train, label_train, color=\"blue\", s=10)\n",
    "plt.scatter(pred_valid, label_valid, color=\"red\", s=10)\n",
    "plt.plot([0, 0.5], [0, 0.5], color=\"black\")\n",
    "plt.xlabel(\"pred\")\n",
    "plt.ylabel(\"label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: prediction using Th2 Cells as lable and svm as model\n",
    "svm = sklearn.svm.SVR().fit(repre_train, profile_train[\"Th2 Cells\"])\n",
    "pred_train = svm.predict(repre_train)\n",
    "pred_valid = svm.predict(repre_valid)\n",
    "mae_train = sklearn.metrics.mean_absolute_error(profile_train[\"Th2 Cells\"], pred_train)\n",
    "mae_valid = sklearn.metrics.mean_absolute_error(profile_valid[\"Th2 Cells\"], pred_valid)\n",
    "print(f\"train mae: {mae_train:.2f}\")\n",
    "print(f\"valid mae: {mae_valid:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile 0: nan to 0\n",
    "# profile 1: remove nan row\n",
    "\n",
    "# representation\n",
    "profile = pd.read_csv(\"data/profile0.csv\")\n",
    "profile = profile.iloc[23:].reset_index(drop=True)\n",
    "repre = np.hstack([\n",
    "    np.load(profile.loc[i, \"repre_path\"]) for i in range(len(profile))\n",
    "    if not pd.isna(profile.loc[i, \"repre_path\"])\n",
    "]).T\n",
    "# for each column, if there are np.nan in that column, drop that column\n",
    "repre = repre[:, np.all(~np.isnan(repre), axis=0)]  # comment for 0, un for 1\n",
    "repre = np.nan_to_num(repre, nan=0.0)\n",
    "# fit\n",
    "visu_pca = sklearn.decomposition.PCA(n_components=8).fit(repre)\n",
    "visu_umap = umap.UMAP(n_components=3).fit(repre)\n",
    "# transform\n",
    "idx = [\n",
    "    i for i in range(len(profile)) if not pd.isna(profile.loc[i, \"repre_path\"])\n",
    "]\n",
    "profile.loc[idx, [f\"pca{p}\" for p in range(8)]] = visu_pca.transform(repre)\n",
    "profile.loc[idx, [f\"umap{u}\" for u in range(3)]] = visu_umap.transform(repre)\n",
    "# save\n",
    "profile.to_csv(\"data/profile2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# { chromosome : (hash_idx, bucket_idx, distance) }\n",
    "feature = Selector(\"data/feature\").getFeature()\n",
    "# remove distance and ndarray dtype from float to int\n",
    "# { chromosome : (hash_idx, bucket_idx) }\n",
    "feature = {c: np.array([f[:2] for f in feature[c]], dtype=int) for c in feature}\n",
    "result = []\n",
    "for c in chromosome_list:\n",
    "    for hash_idx, bucket_idx in feature[c]:\n",
    "        result.append((c, hash_idx*1000 + bucket_idx*100, hash_idx*1000 + (bucket_idx+1)*100))\n",
    "result = pd.DataFrame(result, columns=[\"chromosome\", \"start\", \"end\"])\n",
    "result.to_csv(\"data/temp/feature.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_idx_max = {\n",
    "    \"1\": 249000,  \"2\": 243000,  \"3\": 199000,  \"4\": 191000,\n",
    "    \"5\": 182000,  \"6\": 171000,  \"7\": 160000,  \"8\": 146000,\n",
    "    \"9\": 139000, \"10\": 134000, \"11\": 136000, \"12\": 134000,\n",
    "    \"13\": 115000, \"14\": 108000, \"15\": 102000, \"16\":  91000,\n",
    "    \"17\":  84000, \"18\":  81000, \"19\":  59000, \"20\":  65000,\n",
    "    \"21\":  47000, \"22\":  51000,  \"X\": 157000,\n",
    "}\n",
    "\n",
    "## bed\n",
    "# read bed file\n",
    "bed = pd.read_csv(\n",
    "    \"data/temp/rgc_gxs_v1_hg38.bed\", \n",
    "    sep=\"\\t\", header=0, names=[\"chromosome\", \"start\", \"end\"]\n",
    ")\n",
    "# remove chr prefix\n",
    "bed[\"chromosome\"] = bed[\"chromosome\"].apply(lambda x: x[3:])\n",
    "# keep chromosome 1-22 and X\n",
    "bed = bed[bed['chromosome'].isin(chromosome_list)]\n",
    "# transform bed from range list to one hot\n",
    "bed_one_hot = {\n",
    "    c: np.zeros((hash_idx_max[c] * 1000), dtype=bool) for c in chromosome_list\n",
    "}\n",
    "for _, row in bed.iterrows():\n",
    "    chromosome, start, end = row[['chromosome', 'start', 'end']]\n",
    "    bed_one_hot[chromosome][start:end] = True\n",
    "\n",
    "## feature\n",
    "# { chromosome : (hash_idx, bucket_idx, distance) }\n",
    "feature = Selector(\"data/feature\").getFeature()\n",
    "# remove distance and ndarray dtype from float to int\n",
    "# { chromosome : (hash_idx, bucket_idx) }\n",
    "feature = {c: np.array([f[:2] for f in feature[c]], dtype=int) for c in feature}\n",
    "# transform feature from bucket list to one hot\n",
    "feature_one_hot = {\n",
    "    c: np.zeros((hash_idx_max[c] * 1000), dtype=bool) for c in chromosome_list\n",
    "}\n",
    "for c in feature:\n",
    "    for hash_idx, bucket_idx in feature[c]:\n",
    "        feature_one_hot[c][\n",
    "            hash_idx*1000 + bucket_idx*100 : hash_idx*1000 + (bucket_idx+1)*100\n",
    "        ] = True\n",
    "\n",
    "# calculate overlap\n",
    "for c in bed_one_hot:\n",
    "    overlap = np.logical_and(bed_one_hot[c], feature_one_hot[c])\n",
    "    overlap_bed = (np.sum(overlap) / np.sum(bed_one_hot[c])) * 100 \n",
    "    overlap_feature = (np.sum(overlap) / np.sum(feature_one_hot[c])) * 100\n",
    "    print(\n",
    "        f\"Chromosome {c}:\\t\",\n",
    "        f\"overlap/bed: {np.sum(overlap):7,} / {np.sum(bed_one_hot[c]):9,} = {overlap_bed:5.2f}%\\t\",\n",
    "        f\"overlap/feature: {np.sum(overlap):7,} / {np.sum(feature_one_hot[c]):9,} = {overlap_feature:5.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = 1e-3\n",
    "\n",
    "snps = pd.read_csv(\"data/snps.csv\", usecols=[\"Chr\", \"Pos\", \"Pval\"])\n",
    "# filter by pval < 1e-3\n",
    "snps = snps[snps[\"Pval\"] < p_val][[\"Chr\", \"Pos\"]]\n",
    "# sort by Chr and then Pos\n",
    "snps = snps.sort_values([\"Chr\", \"Pos\"])\n",
    "# transform chromosome from int 1-23 to str 1-22, X\n",
    "snps[\"Chr\"] = snps[\"Chr\"].apply(lambda x: str(x) if x < 23 else \"X\")\n",
    "# split by chromosome, { chromosome : (pos) }\n",
    "snps = snps.groupby(\"Chr\")[\"Pos\"].apply(list).to_dict()\n",
    "\n",
    "for c, pos in snps.items():\n",
    "    snps_in_bed, snps_in_feature = 0, 0\n",
    "    for p in pos:\n",
    "        if bed_one_hot[c][p]: snps_in_bed += 1\n",
    "        if feature_one_hot[c][p]: snps_in_feature += 1\n",
    "    print(\n",
    "        f\"Chromosome {c}:\\t\",\n",
    "        f\"snps_in_bed/bed: {snps_in_bed:6,} / {len(pos):6,} = {(snps_in_bed / len(pos)) * 100:5.2f}%\\t\",\n",
    "        f\"snps_in_feature/feature: {snps_in_feature:6,} / {len(pos):6,} = {(snps_in_feature / len(pos)) * 100:5.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = 1e-2\n",
    "\n",
    "snps = pd.read_csv(\"data/snps.csv\", usecols=[\"Chr\", \"Pos\", \"Pval\"])\n",
    "# filter by pval < 1e-2\n",
    "snps = snps[snps[\"Pval\"] < p_val][[\"Chr\", \"Pos\"]]\n",
    "# sort by Chr and then Pos\n",
    "snps = snps.sort_values([\"Chr\", \"Pos\"])\n",
    "# transform chromosome from int 1-23 to str 1-22, X\n",
    "snps[\"Chr\"] = snps[\"Chr\"].apply(lambda x: str(x) if x < 23 else \"X\")\n",
    "# split by chromosome, { chromosome : (pos) }\n",
    "snps = snps.groupby(\"Chr\")[\"Pos\"].apply(list).to_dict()\n",
    "\n",
    "for c, pos in snps.items():\n",
    "    snps_in_bed, snps_in_feature = 0, 0\n",
    "    for p in pos:\n",
    "        if bed_one_hot[c][p]: snps_in_bed += 1\n",
    "        if feature_one_hot[c][p]: snps_in_feature += 1\n",
    "    print(\n",
    "        f\"Chromosome {c}:\\t\",\n",
    "        f\"snps_in_bed/bed: {snps_in_bed:7,} / {len(pos):7,} = {(snps_in_bed / len(pos)) * 100:5.2f}%\\t\",\n",
    "        f\"snps_in_feature/feature: {snps_in_feature:7,} / {len(pos):7,} = {(snps_in_feature / len(pos)) * 100:5.2f}%\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCGA-Onc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
