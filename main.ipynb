{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fold = \"data/stanford/\"\n",
    "method = \"pretrain\"     # pretrain or finetune\n",
    "isolates = [3, 7]       # for get the selected pos\n",
    "chromosome = \"6\"\n",
    "pval_thresh = 1e-5\n",
    "part = \"top\"            # top, low\n",
    "k_reads = 4000         # 2000, 4000, 12000\n",
    "pos_range = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.decomposition\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "\n",
    "\"\"\" function \"\"\"\n",
    "\n",
    "def getSelectedPos(\n",
    "    embd: dict[str, np.ndarray], part: str, k_reads: int\n",
    ") -> np.ndarray:\n",
    "    runs = list(embd.keys())\n",
    "\n",
    "    # get filter of reads of each sample by Euclidean distance matrix\n",
    "    filter = [[\n",
    "        np.full(len(embd[runs[i]]), False, dtype=bool) for _ in range(len(runs))\n",
    "    ] for i in range(len(runs))]\n",
    "    for i in range(len(runs)):\n",
    "        for j in range(i+1, len(runs)):\n",
    "            x1embd = embd[runs[i]][:, :768]                         # (Ni, 768)\n",
    "            x2embd = embd[runs[j]][:, :768]                         # (Nj, 768)\n",
    "            x1pos  = embd[runs[i]][:,  768]                         # (Ni, )\n",
    "            x2pos  = embd[runs[j]][:,  768]                         # (Nj, )\n",
    "\n",
    "            distance_matrix = torch.cdist(                          # (Ni, Nj)\n",
    "                torch.tensor(x1embd), torch.tensor(x2embd)\n",
    "            ).numpy()\n",
    "\n",
    "            # concate into DataFrame to keep track index\n",
    "            x1df = pd.DataFrame(\n",
    "                {\"distance\": np.max(distance_matrix, axis=1), \"pos\": x1pos}\n",
    "            )\n",
    "            x2df = pd.DataFrame(\n",
    "                {\"distance\": np.max(distance_matrix, axis=0), \"pos\": x2pos}\n",
    "            )\n",
    "\n",
    "            if part == \"top\":   # sort from distance high to low\n",
    "                x1df = x1df.sort_values(by=\"distance\", ascending=False)\n",
    "                x2df = x2df.sort_values(by=\"distance\", ascending=False)\n",
    "            if part == \"low\":   # sort from distance low to high\n",
    "                x1df = x1df.sort_values(by=\"distance\", ascending=True)\n",
    "                x2df = x2df.sort_values(by=\"distance\", ascending=True)\n",
    "\n",
    "            # drop duplicates reads with same position\n",
    "            x1df = x1df.drop_duplicates(subset=\"pos\", keep=\"first\")\n",
    "            x2df = x2df.drop_duplicates(subset=\"pos\", keep=\"first\")\n",
    "\n",
    "            # keep k_reads of head, get there index that match original embd, \n",
    "            # transfer index to one hot filter\n",
    "            filter[i][j][x1df.head(k_reads).index] = True           # (Ni, )\n",
    "            filter[j][i][x2df.head(k_reads).index] = True           # (Nj, )\n",
    "    filter = {runs[i]: np.any(filter[i], axis=0) for i in range(len(runs))}\n",
    "\n",
    "    # get pos that need to be selected\n",
    "    # for each run, get the pos of reads that are selected\n",
    "    pos = {run: embd[run][filter[run]][:, 768] for run in runs}     # {run: (~6000, )}\n",
    "    # combine, remove duplicates, and sort pos of all runs\n",
    "    pos = np.sort(np.unique(np.concatenate([pos[run] for run in runs])))    # (~13000, )\n",
    "\n",
    "    return pos  # (~13000, )\n",
    "\n",
    "def getSelectedEmbd(\n",
    "    embd: np.ndarray, pos: np.ndarray, pos_range: int\n",
    ") -> np.ndarray:\n",
    "    embd_selected = np.zeros([len(pos), 768])   # [~13000, 768]\n",
    "    e = 0   # index for embed\n",
    "    for p in range(len(pos)):\n",
    "        # move e to the first read that is larger than pos[p]-pos_range\n",
    "        # note that both embd and pos are sorted, so for next p, we can directly \n",
    "        # start from previous e\n",
    "        while e < len(embd) and embd[e, 768] < pos[p]-pos_range: e += 1\n",
    "        # if first read that larger than pos[p] - pos_range is also larger than \n",
    "        # pos[p] + pos_range, then we have no read in this range, set the embd of\n",
    "        # this pos to 0; \n",
    "        if embd[e, 768] > pos[p]+pos_range: continue\n",
    "        # if first read that larger than pos[p] - pos_range smaller than \n",
    "        # pos[p] + pos_range, get the reads that closest to pos[p]\n",
    "        e_temp = e\n",
    "        distance = pos_range\n",
    "        while e_temp < len(embd) and embd[e_temp, 768] <= pos[p]+pos_range:\n",
    "            if abs(embd[e_temp, 768] - pos[p]) <= distance:\n",
    "                distance = abs(embd[e_temp, 768] - pos[p])\n",
    "                embd_selected[p] = embd[e_temp, :768]\n",
    "            e_temp += 1\n",
    "    return embd_selected    # [~13000, 768]\n",
    "\n",
    "def pearsonCorrelation(x1: np.ndarray, x2: np.ndarray) -> np.ndarray:\n",
    "    x1centered = x1 - x1.mean(axis=1, keepdims=True)        # (N1, 768)\n",
    "    x2centered = x2 - x2.mean(axis=1, keepdims=True)        # (N2, 768)\n",
    "    numerator = np.dot(x1centered, x2centered.T)            # (N1, N2)\n",
    "    x1var = np.sum(x1centered**2, axis=1, keepdims=True)    # (N1,  1)\n",
    "    x2var = np.sum(x2centered**2, axis=1, keepdims=True)    # (N2,  1)\n",
    "    denominator = np.sqrt(np.dot(x1var, x2var.T))           # (N1, N2)\n",
    "    return numerator / denominator                          # (N1, N2)\n",
    "\n",
    "\"\"\" profile \"\"\"\n",
    "\n",
    "# dataset\n",
    "profile = pd.read_csv(os.path.join(data_fold, \"profile.txt\"))\n",
    "# Isolate string (i.e. su001) -> int (i.e. 1)\n",
    "profile[\"Isolate\"] = profile[\"Isolate\"].apply(lambda x: int(x[2:]))\n",
    "# Treatment pre/post -> 0/1\n",
    "profile[\"Treatment\"] = profile[\"Treatment\"].apply(lambda x: int(not \"pre\" in x))\n",
    "# Sort by Isolate (1 to 8), Treatment (pre to post), and Tissue (normal to BCC)\n",
    "profile = profile.sort_values(\n",
    "    by=[\"Isolate\", \"Treatment\", \"Tissue\"], ascending=[True, True, False]\n",
    ").reset_index(drop=True)\n",
    "# only keep run, isolate, treatment, tissue\n",
    "profile = profile[[\"Run\", \"Isolate\", \"Treatment\", \"Tissue\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selector\n",
    "import importlib\n",
    "importlib.reload(selector)\n",
    "\n",
    "feature = selector.Selector(\"data/feature\", pval_thresh=1e-5, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plot correlation heat map of runs for selected pos\"\"\"\n",
    "\n",
    "# runs used for get selected pos\n",
    "runs = []\n",
    "for isolate in isolates:\n",
    "    runs += profile[profile[\"Isolate\"] == isolate][\"Run\"].to_list()\n",
    "\n",
    "# embd after snps and pos filter, len(runs) * [~13000, 768]\n",
    "embd = {}\n",
    "for run in runs:\n",
    "    embd[run] = np.load(os.path.join(data_fold, f\"embd-{method}/{run}/{chromosome}.npy\"))\n",
    "    # [~40k, 776]\n",
    "    embd[run] = embd[run][embd[run][:, 769-int(np.log10(pval_thresh))]>=1, :] \n",
    "    # [~13000, 768]\n",
    "    embd[run] = getSelectedEmbd(embd[run], pos, pos_range)\n",
    "\n",
    "# pca of embd, use pca1 to represent each run\n",
    "# len(runs) * [~13000, 768] -> [len(runs), ~13000]\n",
    "pca_reducer = sklearn.decomposition.PCA(n_components=1)\n",
    "pca_reducer.fit(np.concatenate([embd[run][:, :768] for run in runs], axis=0))\n",
    "pca = np.array([pca_reducer.transform(embd[run][:, :768]) for run in runs])[:, :, 0]\n",
    "\n",
    "# calculate the correlation between each pair of runs\n",
    "heat_map = pearsonCorrelation(pca, pca)     # [len(runs), len(runs)]\n",
    "for i in range(len(heat_map)): heat_map[i, i] = np.nan\n",
    "\n",
    "# plot the heat map 6*6 \n",
    "labels = []\n",
    "for run in runs:\n",
    "    id, isolate, treatment, tissue = profile[profile[\"Run\"] == run].iloc[0]\n",
    "    labels.append(\"{}-{}-{}-{}\".format(\n",
    "            id, isolate,\n",
    "            \"Pre\" if treatment == 0 else \"Post\", \n",
    "            \"Normal\" if \"normal\" in tissue else \"Tumor\"\n",
    "        ))\n",
    "plt.figure(dpi=300)\n",
    "sns.heatmap(\n",
    "    heat_map, annot=True, fmt=\".3f\", cmap=\"coolwarm\", square=True,\n",
    "    yticklabels=labels, xticklabels=False\n",
    ")\n",
    "plt.title(\"Pearson Correlation\", fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plot scatter of PCA1 and PCA2 of all runs \"\"\"\n",
    "\n",
    "# runs we will plot\n",
    "runs = profile[\"Run\"].to_list()\n",
    "\n",
    "# embd after snps and pos filter, len(runs) * [~13000, 768]\n",
    "embd = {}\n",
    "for run in runs:\n",
    "    embd[run] = np.load(os.path.join(data_fold, f\"embd-{method}/{run}/{chromosome}.npy\"))\n",
    "    # [~40k, 776]\n",
    "    embd[run] = embd[run][embd[run][:, 769-int(np.log10(pval_thresh))]>=1, :] \n",
    "    # [~13000, 768]\n",
    "    embd[run] = getSelectedEmbd(embd[run], pos, pos_range)\n",
    "\n",
    "# pca of embd, use pca1 to represent each run\n",
    "# len(runs) * [~13000, 768] -> [len(runs), ~13000]\n",
    "pca_reducer = sklearn.decomposition.PCA(n_components=5)\n",
    "pca_reducer.fit(np.concatenate([embd[run][:, :768] for run in runs], axis=0))\n",
    "pca = np.array([pca_reducer.transform(embd[run][:, :768]) for run in runs])[:, :, 0]\n",
    "\n",
    "print(pca_reducer.explained_variance_ratio_)\n",
    "\n",
    "# [len(runs), ~13000] -> [len(runs), 2], for plot\n",
    "pca = sklearn.decomposition.PCA(n_components=2).fit_transform(pca)\n",
    "\n",
    "# plot scatter of PCA1 and PCA2\n",
    "labels = []\n",
    "for run in runs:\n",
    "    id, isolate, treatment, tissue = profile[profile[\"Run\"] == run].iloc[0]\n",
    "    labels.append(\"{}-{}\".format(id, isolate,))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True, dpi=300)\n",
    "# color by isolate\n",
    "colors = [f\"C{i}\" for i in range(8)]\n",
    "axs[0].scatter(pca[:, 0], pca[:, 1], c=[colors[profile[profile[\"Run\"] == run].iloc[0][\"Isolate\"]-1] for run in runs])\n",
    "for i in range(len(runs)):\n",
    "    axs[0].text(pca[i, 0], pca[i, 1], labels[i], fontsize=3)\n",
    "axs[0].legend(\n",
    "    handles=[\n",
    "        matplotlib.patches.Patch(color=colors[i], label=f\"Isolate {i+1}\") for i in range(8)\n",
    "    ], loc=\"upper right\", ncol=1,\n",
    ")\n",
    "# color by treatment\n",
    "colors = [\"red\" if profile[profile[\"Run\"] == run].iloc[0][\"Treatment\"] == 0 else \"blue\" for run in runs]\n",
    "axs[1].scatter(pca[:, 0], pca[:, 1], c=colors)\n",
    "for i in range(len(runs)):\n",
    "    axs[1].text(pca[i, 0], pca[i, 1], labels[i], fontsize=3)\n",
    "axs[1].legend(\n",
    "    handles=[\n",
    "        matplotlib.patches.Patch(color=\"r\", label=\"pre \"), \n",
    "        matplotlib.patches.Patch(color=\"b\", label=\"post\")\n",
    "    ], loc=\"upper right\", ncol=1,\n",
    ")\n",
    "# color by tissue\n",
    "colors = [\"green\" if \"normal\" in profile[profile[\"Run\"] == run].iloc[0][\"Tissue\"] else \"purple\" for run in runs]\n",
    "axs[2].scatter(pca[:, 0], pca[:, 1], c=colors)\n",
    "for i in range(len(runs)):\n",
    "    axs[2].text(pca[i, 0], pca[i, 1], labels[i], fontsize=3)\n",
    "axs[2].legend(\n",
    "    handles=[\n",
    "        matplotlib.patches.Patch(color=\"g\", label=\"normal\"), \n",
    "        matplotlib.patches.Patch(color=\"purple\", label=\"BCC\")\n",
    "    ], loc=\"upper right\", ncol=1,\n",
    ")\n",
    "fig.suptitle(f\"Selected Pos from isolates {isolates}\", fontweight='bold')\n",
    "fig.supxlabel(\"PCA1\", fontweight='bold')\n",
    "fig.supylabel(\"PCA2\", fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plot Distribution of Euclidean Distance \"\"\"\n",
    "\n",
    "bins = 100\n",
    "fontsize = 14\n",
    "\n",
    "# runs used for get selected pos\n",
    "runs = []\n",
    "for isolate in isolates:\n",
    "    runs += profile[profile[\"Isolate\"] == isolate][\"Run\"].to_list()\n",
    "\n",
    "temp_embd = {}\n",
    "for run in runs:\n",
    "    temp_embd[run] = np.load(os.path.join(data_fold, f\"embd-{method}/{run}/{chromosome}.npy\"))\n",
    "    temp_embd[run] = temp_embd[run][temp_embd[run][:, 769-int(np.log10(pval_thresh))]>=1, :]\n",
    "\n",
    "x1embd = temp_embd[runs[0]][:, :768]     # (N1, 768)\n",
    "x2embd = temp_embd[runs[3]][:, :768]     # (N2, 768)\n",
    "distance_matrix = torch.cdist(      # (N1, N2)\n",
    "    torch.tensor(x1embd), torch.tensor(x2embd)\n",
    ").numpy()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "for i in range(2):\n",
    "    axs[i].hist(np.max(distance_matrix, axis=int(not i)), bins=bins)\n",
    "    # title\n",
    "    id, isolate, treatment, tissue = profile[profile[\"Run\"] == runs[i]].iloc[0]\n",
    "    axs[i].set_title(\n",
    "        \"{}-{}-{}-{}\".format(\n",
    "            id, isolate, \n",
    "            \"Pre\" if treatment == 0 else \"Post\", \n",
    "            \"Normal\" if \"normal\" in tissue else \"Tumor\"\n",
    "        ), \n",
    "        fontweight='bold', fontsize=fontsize\n",
    "    )\n",
    "    # axis\n",
    "    axs[i].set_xlim(5, 11)\n",
    "fig.supxlabel(\"Euclidean Distance\", fontweight='bold', y=0.004, fontsize=fontsize)\n",
    "fig.supylabel(\"Number of Reads\", fontweight='bold', x=0.008, fontsize=fontsize)\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot Hexbin N * N+1\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "gridsize = 80\n",
    "vmin, vmax = 4, 64\n",
    "fontsize = 18\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(runs), len(runs)+1, figsize=(35, 30), \n",
    "    sharex=True, sharey=True\n",
    ")\n",
    "# plot\n",
    "for i in range(len(runs)):\n",
    "    # plot umpa of sample i before filter in diagonal\n",
    "    axs[i, i].hexbin(\n",
    "        umap[runs[i]][:, 0], umap[runs[i]][:, 1], \n",
    "        cmap=\"Reds\", gridsize=gridsize, vmin=vmin, vmax=vmax,\n",
    "    )\n",
    "    # plot umap of (i, :) and (:, i) after filter by distance (i, j)\n",
    "    for j in range(i+1, len(runs)):\n",
    "        # umap of (i, :)\n",
    "        axs[i, j].hexbin(\n",
    "            umap[runs[i]][:, 0], umap[runs[i]][:, 1], \n",
    "            cmap=\"Reds\", gridsize=gridsize, vmin=vmin, vmax=vmax/2,\n",
    "        )\n",
    "        # umap of (:, i)\n",
    "        axs[j, i].hexbin(\n",
    "            umap[runs[j]][:, 0], umap[runs[j]][:, 1], \n",
    "            cmap=\"Reds\", gridsize=gridsize, vmin=vmin, vmax=vmax/2,\n",
    "        )\n",
    "    # plot umap of (i, len(runs)) of combine all filter\n",
    "    axs[i, len(runs)].hexbin(\n",
    "        umap[runs[i]][:, 0], \n",
    "        umap[runs[i]][:, 1], \n",
    "        cmap=\"Reds\", gridsize=gridsize, vmin=vmin, vmax=vmax/2,\n",
    "    )\n",
    "# set up axis and label\n",
    "for i in range(len(runs)):\n",
    "    id, isolate, treatment, tissue = profile[profile[\"Run\"] == runs[i]].iloc[0]\n",
    "    treatment = \"Pre\" if treatment == 0 else \"Post\"\n",
    "    tissue = \"Normal\" if \"normal\" in tissue else \"Tumor\"\n",
    "    info = f\"{id} - {isolate} - {treatment} - {tissue}\"\n",
    "    axs[0,  i].set_xlabel(info, fontsize=fontsize, fontweight='bold')\n",
    "    axs[0,  i].xaxis.set_label_position(\"top\")\n",
    "    axs[0, len(runs)].set_xlabel(\"All Selected Reads\", fontsize=fontsize, fontweight='bold')\n",
    "    axs[0, len(runs)].xaxis.set_label_position(\"top\")\n",
    "    axs[i, -1].set_ylabel(info, fontsize=fontsize, fontweight='bold')\n",
    "    axs[i, -1].yaxis.set_label_position(\"right\")\n",
    "    for j in range(len(runs)+1):\n",
    "        axs[i, j].set_aspect(\"equal\")\n",
    "        axs[i, j].set_xlim(-22, 22)\n",
    "        axs[i, j].set_ylim(-22, 22)\n",
    "fig.supxlabel(\"UMAP1\", fontsize=fontsize, fontweight='bold', y=0.004)\n",
    "fig.supylabel(\"UMAP2\", fontsize=fontsize, fontweight='bold', x=0.008)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"temp.png\", dpi=500)\n",
    "fig.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot Hexbin of all samples \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "gridsize = 80\n",
    "vmin, vmax = 4, 64\n",
    "fontsize = 18\n",
    "\n",
    "# hexbin, split by isolate\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "umap_isolates = [None, None]\n",
    "for i in range(len(runs)):\n",
    "    axs_index = 0 if profile[profile[\"Run\"] == runs[i]][\"Isolate\"].values[0] == 3 else 1\n",
    "    if umap_isolates[axs_index] is None:\n",
    "        umap_isolates[axs_index] = umap[runs[i]]\n",
    "    else:\n",
    "        umap_isolates[axs_index] = np.concatenate(\n",
    "            [umap_isolates[axs_index], umap[runs[i]]]\n",
    "        )\n",
    "for axs_index in range(2):\n",
    "    axs[axs_index].hexbin(\n",
    "        umap_isolates[axs_index][:, 0], umap_isolates[axs_index][:, 1], \n",
    "        cmap=\"Reds\", gridsize=gridsize, vmin=vmin, vmax=vmax,\n",
    "    )\n",
    "    axs[axs_index].set_xlim(-22, 22)\n",
    "    axs[axs_index].set_ylim(-22, 22)\n",
    "    axs[axs_index].set_title(\n",
    "        \"su003\" if axs_index == 0 else \"su007\", \n",
    "        fontweight='bold', fontsize=fontsize\n",
    "    )\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "# hexbin, split by treatment\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "umap_treatments = [None, None]\n",
    "for i in range(len(runs)):\n",
    "    axs_index = profile[profile[\"Run\"] == runs[i]][\"Treatment\"].values[0]\n",
    "    if umap_treatments[axs_index] is None:\n",
    "        umap_treatments[axs_index] = umap[runs[i]]\n",
    "    else:\n",
    "        umap_treatments[axs_index] = np.concatenate(\n",
    "            [umap_treatments[axs_index], umap[runs[i]]]\n",
    "        )\n",
    "for axs_index in range(2):\n",
    "    axs[axs_index].hexbin(\n",
    "        umap_treatments[axs_index][:, 0], umap_treatments[axs_index][:, 1], \n",
    "        cmap=\"Reds\", gridsize=gridsize,\n",
    "        vmin = vmin if axs_index == 0 else (vmin/2),\n",
    "        vmax = vmax if axs_index == 0 else (vmax/2)\n",
    "    )\n",
    "    axs[axs_index].set_xlim(-22, 22)\n",
    "    axs[axs_index].set_ylim(-22, 22)\n",
    "    axs[axs_index].set_title(\n",
    "        \"Pre\" if axs_index == 0 else \"Post\", \n",
    "        fontweight='bold', fontsize=fontsize\n",
    "    )\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCGA-Onc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
